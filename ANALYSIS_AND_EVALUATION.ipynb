{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "class Word2Vec :\n",
    "    def __init__ ( self , model_file_path ) :\n",
    "        self.__model_path__ = model_file_path\n",
    "        self.__word_embeddings__ = None\n",
    "        self.__word_to_id_map__ = None\n",
    "        self.__id_to_word_map__ = None\n",
    "        import pickle\n",
    "        with open(model_file_path, 'rb') as model_file :\n",
    "            word2vec_model = pickle.load(model_file)\n",
    "            self.__word_embeddings__ = word2vec_model['WORD_EMBEDDINGS']\n",
    "            self.__word_to_id_map__ = word2vec_model['WORD_TO_ID']\n",
    "            self.__id_to_word_map__ = word2vec_model['ID_TO_WORD']\n",
    "    \n",
    "    def __getitem__ ( self , query ) :\n",
    "        if ( isinstance(query, str) ) :\n",
    "            query = query.lower()\n",
    "            if ( not query in self.__word_to_id_map__ ) :\n",
    "                return None\n",
    "            return self.__word_embeddings__[self.__word_to_id_map__[query]]\n",
    "        return None\n",
    "    \n",
    "    def CosineSimilarity ( self , word1 , word2 ) :\n",
    "        vec1 , vec2 = None , None\n",
    "        if ( isinstance(word1, str) ) : vec1 = self[word1]\n",
    "        elif ( isinstance(word1, np.ndarray) ) : vec1 = word1\n",
    "        else : return None\n",
    "        if ( isinstance(word2, str) ) : vec2 = self[word2]\n",
    "        elif ( isinstance(word2, np.ndarray) ) : vec2 = word2\n",
    "        else : return None\n",
    "        dot_product = abs(vec1.dot(vec2))\n",
    "        mag1 = np.linalg.norm(vec1)\n",
    "        mag2 = np.linalg.norm(vec2)\n",
    "        similarity = dot_product / ( mag1 * mag2 )\n",
    "        return round(similarity, 4)\n",
    "\n",
    "    def GetMostSimilar ( self , query , limit = 10 ) :\n",
    "        if ( isinstance(query, str) ) :\n",
    "            query = query.lower()\n",
    "            if ( not query in self.__word_to_id_map__ ) : return []\n",
    "        similarities = list()\n",
    "        for word in self.__word_to_id_map__ :\n",
    "            similarities.append((word, self.CosineSimilarity(word, query)))\n",
    "        similarities.sort(key = lambda x : -1*x[1])\n",
    "        return similarities[:limit]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec('MODELS/WORD_2_VEC_MODEL_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis On Analogical Reasoning Tasks\n",
    "These tasks check the ability of the model to automatically organize concepts and learn implicitly the relationships between them, as during the training we did not provide any supervised information about what a capital city means or how a father-mother semantic relationship is related to a son-daughter semantic relationship.\n",
    "The calibre of the model is analysed on three types of analogical tasks.\n",
    "<ol>\n",
    " <li> &nbsp;&nbsp;word1&nbsp; +&nbsp; word2&nbsp; ≈&nbsp; word3\n",
    " <li> &nbsp;&nbsp;word1&nbsp; -&nbsp; word2&nbsp; +&nbsp; word3&nbsp; ≈&nbsp; word4\n",
    " <li> &nbsp;&nbsp;word1&nbsp; ≈&nbsp; word2\n",
    "<ol/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('switzerland', 0.9061),\n",
       " ('romansh', 0.6188),\n",
       " ('language', 0.5997),\n",
       " ('sweden', 0.4396),\n",
       " ('netherlands', 0.4315),\n",
       " ('estonia', 0.4269),\n",
       " ('neue', 0.3873),\n",
       " ('ambassador', 0.3857),\n",
       " ('iceland', 0.3848),\n",
       " ('hayti', 0.3801),\n",
       " ('resorts', 0.3736),\n",
       " ('germany', 0.3722),\n",
       " ('belgium', 0.3697),\n",
       " ('bern', 0.3619),\n",
       " ('primates', 0.3609)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Switzerland'] + model['language']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Romansh is the official language of Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bangladesh', 0.9494),\n",
       " ('language', 0.5986),\n",
       " ('importers', 0.4201),\n",
       " ('ul', 0.3928),\n",
       " ('bengali', 0.3886),\n",
       " ('enhanced', 0.3849),\n",
       " ('cleric', 0.3711),\n",
       " ('arnett', 0.3625),\n",
       " ('tamil', 0.3564),\n",
       " ('labs', 0.3522),\n",
       " ('graffiti', 0.3486),\n",
       " ('insensitivity', 0.3462),\n",
       " ('parthenos', 0.3444),\n",
       " ('infiltration', 0.3429),\n",
       " ('tabletop', 0.342)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Bangladesh'] + model['language']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Bengali is the official language of Bangladesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('river', 0.8196),\n",
       " ('india', 0.7531),\n",
       " ('yamuna', 0.5334),\n",
       " ('madras', 0.5002),\n",
       " ('haidarabad', 0.4877),\n",
       " ('peninsula', 0.483),\n",
       " ('n', 0.4797),\n",
       " ('persia', 0.473),\n",
       " ('e', 0.4647),\n",
       " ('mysore', 0.4634),\n",
       " ('siberia', 0.4618),\n",
       " ('berar', 0.458),\n",
       " ('china', 0.4574),\n",
       " ('rajputana', 0.4508),\n",
       " ('central', 0.4468)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['India'] + model['river']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Yamuna is a river in India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('greece', 0.8148),\n",
       " ('river', 0.7718),\n",
       " ('haliacmon', 0.5801),\n",
       " ('magnesia', 0.4651),\n",
       " ('adige', 0.4567),\n",
       " ('haidarabad', 0.441),\n",
       " ('amazonas', 0.4399),\n",
       " ('yangtze', 0.4382),\n",
       " ('ebro', 0.4376),\n",
       " ('corrientes', 0.4346),\n",
       " ('provs', 0.4334),\n",
       " ('berar', 0.4282),\n",
       " ('baluchistan', 0.4226),\n",
       " ('warta', 0.422),\n",
       " ('indo-china', 0.4133)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Greece'] + model['river']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Haliacmon is a river in Greece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('singer', 0.8331),\n",
       " ('spanish', 0.7789),\n",
       " ('shakira', 0.6714),\n",
       " ('ricky-martin', 0.6524),\n",
       " ('iglesias', 0.56),\n",
       " ('beyonce', 0.5461),\n",
       " ('justin-bieber', 0.5093),\n",
       " ('taylor-swift', 0.4968),\n",
       " ('chicanos', 0.4369),\n",
       " ('rael', 0.436),\n",
       " ('folk', 0.4332),\n",
       " ('mexicans', 0.4238),\n",
       " ('sargent', 0.4194),\n",
       " ('tamale', 0.41),\n",
       " ('bbq', 0.4058)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Spanish'] + model['singer']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Shakira, Ricky Marin, Iglesias are Spanish singers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('singer', 0.9018),\n",
       " ('american', 0.6391),\n",
       " ('beyonce', 0.5936),\n",
       " ('justin-bieber', 0.5756),\n",
       " ('shakira', 0.5636),\n",
       " ('taylor-swift', 0.562),\n",
       " ('ricky-martin', 0.5311),\n",
       " ('bashevis', 0.5012),\n",
       " ('sargent', 0.4752),\n",
       " ('iglesias', 0.4663),\n",
       " ('isaac', 0.4429),\n",
       " ('nine', 0.4326),\n",
       " ('gaga', 0.432),\n",
       " ('straus', 0.4248),\n",
       " ('d.d.s', 0.4181)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['American'] + model['singer']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Beyonce, Justin Beiber, Taylor Swift, Lady Gaga are American singers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spain', 0.735),\n",
       " ('moscow', 0.5464),\n",
       " ('ebro', 0.4454),\n",
       " ('madrid', 0.4057),\n",
       " ('rosas', 0.397),\n",
       " ('franco', 0.3749),\n",
       " ('plata', 0.3659),\n",
       " ('revolted', 0.3634),\n",
       " ('valencia', 0.3544),\n",
       " ('ecclesiastical', 0.3539),\n",
       " ('spanish', 0.3475),\n",
       " ('condado', 0.3452),\n",
       " ('rosario', 0.3446),\n",
       " ('pizarro', 0.3418),\n",
       " ('palacio', 0.3367)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Moscow'] - model['Russia'] + model['Spain']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Moscow is the capital of Russia. Madrid is the capital of Spain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('madrid', 0.6781),\n",
       " ('river', 0.6539),\n",
       " ('spain', 0.4251),\n",
       " ('n', 0.4171),\n",
       " ('west', 0.4011),\n",
       " ('el', 0.3923),\n",
       " ('indies', 0.3814),\n",
       " ('ebro', 0.3767),\n",
       " ('siberia', 0.3662),\n",
       " ('cortes', 0.3662),\n",
       " ('north', 0.3639),\n",
       " ('peru', 0.355),\n",
       " ('nebraska', 0.354),\n",
       " ('amazonas', 0.3531),\n",
       " ('ki', 0.3481)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Madrid'] - model['capital'] + model['river']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Madrid is the capital of Spain. Ebro is a river in Spain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('warsaw', 0.7173),\n",
       " ('river', 0.6149),\n",
       " ('krak', 0.4158),\n",
       " ('warta', 0.3983),\n",
       " ('poland', 0.393),\n",
       " ('poznan', 0.3782),\n",
       " ('haliacmon', 0.3745),\n",
       " ('peninsula', 0.3637),\n",
       " ('seine', 0.3585),\n",
       " ('ebro', 0.352),\n",
       " ('lima', 0.3497),\n",
       " ('goyaz', 0.3496),\n",
       " ('n.y', 0.3451),\n",
       " ('plata', 0.3426),\n",
       " ('ul', 0.3418)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Warsaw'] - model['capital'] + model['river']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Warsaw is the capital of Poland. Warta is a river in Poland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('valencia', 0.6156),\n",
       " ('chile', 0.5261),\n",
       " ('valparaiso', 0.3929),\n",
       " ('desert', 0.2923),\n",
       " ('swam', 0.2866),\n",
       " ('venezuela', 0.2837),\n",
       " ('healed', 0.2694),\n",
       " ('qiagen', 0.2674),\n",
       " ('paella', 0.2476),\n",
       " ('invitrogen', 0.2456),\n",
       " ('git', 0.2452),\n",
       " ('kit', 0.2437),\n",
       " ('lahore', 0.2434),\n",
       " ('aquincum', 0.2346),\n",
       " ('locally', 0.2342)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Chile'] - model['Valparaiso'] + model['Valencia']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Valparaiso is a city in Chile. Valenica is a city in Venezuela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yamuna', 0.7809),\n",
       " ('greece', 0.6608),\n",
       " ('haliacmon', 0.5679),\n",
       " ('magnesia', 0.4748),\n",
       " ('ebro', 0.4728),\n",
       " ('warta', 0.4505),\n",
       " ('yangtze', 0.4281),\n",
       " ('adige', 0.4279),\n",
       " ('turn-off', 0.4231),\n",
       " ('henriques', 0.4172),\n",
       " ('weel', 0.4098),\n",
       " ('cost-per-case', 0.4044),\n",
       " ('mycenaean', 0.4024),\n",
       " ('dioramas', 0.4009),\n",
       " ('henequen', 0.4005)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Yamuna'] - model['India'] + model['Greece']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Yamuna is a river in India. Haliacmon is a river in Greece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dhoni', 0.7686),\n",
       " ('football', 0.5217),\n",
       " ('serena-williams', 0.4607),\n",
       " ('messi', 0.4488),\n",
       " ('coastal', 0.4342),\n",
       " ('zidane', 0.4317),\n",
       " ('dinghy', 0.4301),\n",
       " ('ronaldo', 0.4261),\n",
       " ('neymar', 0.4182),\n",
       " ('buoy', 0.4055),\n",
       " ('djokovic', 0.3915),\n",
       " ('ioannidis', 0.3888),\n",
       " ('embo', 0.3874),\n",
       " ('straddling', 0.386),\n",
       " ('inlets', 0.3843)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Dhoni'] - model['cricket'] + model['football']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Dhoni is a cricket player. Messi, Ronaldo, Neymar are football players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dhoni', 0.7401),\n",
       " ('tennis', 0.6251),\n",
       " ('serena-williams', 0.5404),\n",
       " ('federer', 0.5275),\n",
       " ('djokovic', 0.4942),\n",
       " ('huatulco', 0.4587),\n",
       " ('sod', 0.4273),\n",
       " ('buoy', 0.4237),\n",
       " ('m.g', 0.4088),\n",
       " ('coastal', 0.4063),\n",
       " ('dinghy', 0.4036),\n",
       " ('slacks', 0.4008),\n",
       " ('fishing', 0.3966),\n",
       " ('parque', 0.3931),\n",
       " ('windsurfing', 0.3908)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Dhoni'] - model['cricket'] + model['tennis']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Dhoni is a cricket player. Serena Williams, Federer, Djokovic are tennis players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dhoni', 0.7444),\n",
       " ('singer', 0.5684),\n",
       " ('beyonce', 0.4885),\n",
       " ('justin-bieber', 0.4701),\n",
       " ('dinghy', 0.4566),\n",
       " ('taylor-swift', 0.4553),\n",
       " ('coastal', 0.4408),\n",
       " ('microarray', 0.4302),\n",
       " ('m.g', 0.4209),\n",
       " ('microbial', 0.4101),\n",
       " ('southerly', 0.4065),\n",
       " ('huatulco', 0.4013),\n",
       " ('sycamore', 0.3997),\n",
       " ('truscott', 0.3993),\n",
       " ('tetramin', 0.3975)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Dhoni'] - model['cricket'] + model['singer']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Dhoni is a cricket player. Beyonce, Justin Beiber, Taylor Swift are singers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beyonce', 0.9043),\n",
       " ('ricky-martin', 0.6254),\n",
       " ('shakira', 0.6176),\n",
       " ('spanish', 0.5903),\n",
       " ('singer', 0.5635),\n",
       " ('justin-bieber', 0.5401),\n",
       " ('taylor-swift', 0.493),\n",
       " ('iglesias', 0.4683),\n",
       " ('chicanos', 0.4348),\n",
       " ('californios', 0.4342),\n",
       " ('burritos', 0.4327),\n",
       " ('mixteco', 0.4318),\n",
       " ('corrientes', 0.4258),\n",
       " ('mestizos', 0.4247),\n",
       " ('frijoles', 0.422)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['Beyonce'] - model['American'] + model['Spanish']\n",
    "model.GetMostSimilar(vec, 15)\n",
    "# Beyonce is an American singer. Ricky Martin, Shakira, Iglesias are Spanish singers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('father', 0.7147),\n",
       " ('woman', 0.713),\n",
       " ('live-in', 0.3987),\n",
       " ('daughter', 0.3925),\n",
       " ('mother', 0.3762),\n",
       " ('lady', 0.3592),\n",
       " ('husband', 0.3512),\n",
       " ('half-sister', 0.3403),\n",
       " ('elder', 0.3336),\n",
       " ('maternity', 0.3334),\n",
       " ('doctor', 0.3314),\n",
       " ('lucie', 0.3292),\n",
       " ('after-school', 0.3251),\n",
       " ('sister', 0.323),\n",
       " ('betty', 0.3213)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['father'] - model['man'] + model['woman']\n",
    "model.GetMostSimilar(vec, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boy', 0.7399),\n",
       " ('woman', 0.6875),\n",
       " ('girl', 0.3658),\n",
       " ('ingraham', 0.3448),\n",
       " ('parents', 0.3404),\n",
       " ('live-in', 0.3331),\n",
       " ('girls', 0.3312),\n",
       " ('sari', 0.3279),\n",
       " ('elder', 0.3235),\n",
       " ('infirmities', 0.3176),\n",
       " ('cuddling', 0.3172),\n",
       " ('jinks', 0.3168),\n",
       " ('chubby', 0.3139),\n",
       " ('kids', 0.3136),\n",
       " ('lady', 0.3133)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['boy'] - model['man'] + model['woman']\n",
    "model.GetMostSimilar(vec, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('walking', 0.6299),\n",
       " ('run', 0.5617),\n",
       " ('fastball', 0.2952),\n",
       " ('ill-timed', 0.2885),\n",
       " ('runaways', 0.2777),\n",
       " ('shortstop', 0.2771),\n",
       " ('planters', 0.2671),\n",
       " ('away', 0.264),\n",
       " ('birthday', 0.263),\n",
       " ('running', 0.2597),\n",
       " ('shuttling', 0.2587),\n",
       " ('thoughtfully', 0.2576),\n",
       " ('braund', 0.2555),\n",
       " ('thor', 0.255),\n",
       " ('bowler', 0.254)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = model['walking'] - model['walk'] + model['run']\n",
    "model.GetMostSimilar(vec, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('singer', 1.0),\n",
       " ('beyonce', 0.5809),\n",
       " ('taylor-swift', 0.5696),\n",
       " ('shakira', 0.5559),\n",
       " ('justin-bieber', 0.5555),\n",
       " ('ricky-martin', 0.5318),\n",
       " ('bashevis', 0.4569),\n",
       " ('iglesias', 0.4454),\n",
       " ('gayle', 0.4185),\n",
       " ('sargent', 0.4045),\n",
       " ('straus', 0.3956),\n",
       " ('coraghessan', 0.3871),\n",
       " ('bbq', 0.3856),\n",
       " ('songwriters', 0.3803),\n",
       " ('isaac', 0.3788)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GetMostSimilar('singer', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('plays', 1.0),\n",
       " ('serena-williams', 0.5738),\n",
       " ('messi', 0.5581),\n",
       " ('tendulkar', 0.5512),\n",
       " ('neymar', 0.5372),\n",
       " ('djokovic', 0.5166),\n",
       " ('federer', 0.486),\n",
       " ('gayle', 0.4588),\n",
       " ('cricket', 0.436),\n",
       " ('dhoni', 0.4329),\n",
       " ('football', 0.4262),\n",
       " ('dramatist', 0.4008),\n",
       " ('ronaldo', 0.3913),\n",
       " ('endocytosis', 0.3888),\n",
       " ('zidane', 0.3875)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GetMostSimilar('plays', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paraguay', 1.0),\n",
       " ('asuncion', 0.5381),\n",
       " ('bolivia', 0.5298),\n",
       " ('oviedo', 0.4938),\n",
       " ('uruguay', 0.4691),\n",
       " ('venezuela', 0.4583),\n",
       " ('peru', 0.4538),\n",
       " ('belgrano', 0.4532),\n",
       " ('brazil', 0.4449),\n",
       " ('guiana', 0.443),\n",
       " ('rosas', 0.4221),\n",
       " ('s.a', 0.4142),\n",
       " ('ecuador', 0.412),\n",
       " ('ayres', 0.4088),\n",
       " ('mendoza', 0.4087)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GetMostSimilar('Paraguay', 15)\n",
    "# Asuncion is the capital of Paraguay. \n",
    "# Bolivia, Uruguay, Venezuela, Peru, Brazil, Ecuador are all countries in South America, like Paraguay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('india', 1.0),\n",
       " ('yamuna', 0.4626),\n",
       " ('malleson', 0.4117),\n",
       " ('hindu', 0.3851),\n",
       " ('mysore', 0.3826),\n",
       " ('persia', 0.3739),\n",
       " ('pakistan', 0.3706),\n",
       " ('madras', 0.3687),\n",
       " ('central', 0.3677),\n",
       " ('coinage', 0.3562),\n",
       " ('battles', 0.3549),\n",
       " ('berar', 0.3528),\n",
       " ('rupee', 0.3465),\n",
       " ('turtons', 0.344),\n",
       " ('coins', 0.3408)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GetMostSimilar('India', 15)\n",
    "# Yamuna is a river in India.\n",
    "# Berar is an ancient province of India.\n",
    "# Mysore and Madras are cities in India.\n",
    "# Rupee is the currency of India.\n",
    "# Hindu is an Indian religion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('canada', 1.0),\n",
       " ('whoa', 0.4497),\n",
       " ('athabasca', 0.4456),\n",
       " ('u.s.a', 0.4418),\n",
       " ('w', 0.438),\n",
       " ('ontario', 0.4368),\n",
       " ('manitoba', 0.4259),\n",
       " ('anticosti', 0.4193),\n",
       " ('yukon', 0.4116),\n",
       " ('canadian', 0.4102),\n",
       " ('inlet', 0.4077),\n",
       " ('alberta', 0.4025),\n",
       " ('newfoundland', 0.4001),\n",
       " ('isthmus', 0.3991),\n",
       " ('quebec', 0.3971)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GetMostSimilar('Canada', 15)\n",
    "# Athabasca is a town in Canadian.\n",
    "# Quebec is a city in Canada.\n",
    "# Anticosti is an island in Canada.\n",
    "# Ontario, Manitoba, Yukon, Alberta, Newfoundland are all Canadian provinces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('monday', 1.0),\n",
       " ('tuesday', 0.6061),\n",
       " ('sessions', 0.5851),\n",
       " ('biennial', 0.5775),\n",
       " ('elections', 0.5716),\n",
       " ('meeting', 0.5598),\n",
       " ('legislature', 0.5532),\n",
       " ('wednesday', 0.5527),\n",
       " ('january', 0.5526),\n",
       " ('odd-numbered', 0.547),\n",
       " ('even-numbered', 0.5417),\n",
       " ('quadrennially', 0.5217),\n",
       " ('session', 0.5212),\n",
       " ('november', 0.5201),\n",
       " ('representatives', 0.5049)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GetMostSimilar('Monday', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('december', 1.0),\n",
       " ('january', 0.4891),\n",
       " ('even-numbered', 0.4281),\n",
       " ('biennial', 0.4244),\n",
       " ('d-del', 0.4214),\n",
       " ('month', 0.4159),\n",
       " ('monday', 0.4036),\n",
       " ('meeting', 0.3918),\n",
       " ('september', 0.3886),\n",
       " ('tuesday', 0.3814),\n",
       " ('nine', 0.3772),\n",
       " ('atta', 0.3693),\n",
       " ('october', 0.3689),\n",
       " ('d.c', 0.3666),\n",
       " ('haig', 0.3616)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GetMostSimilar('December', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('zero', 1.0),\n",
       " ('nine', 0.6839),\n",
       " ('five', 0.6709),\n",
       " ('four', 0.6341),\n",
       " ('seven', 0.6272),\n",
       " ('approximately', 0.5852),\n",
       " ('million', 0.5828),\n",
       " ('six', 0.5706),\n",
       " ('eight', 0.5652),\n",
       " ('percent', 0.5599),\n",
       " ('billion', 0.4853),\n",
       " ('year', 0.4818),\n",
       " ('mctwo', 0.4766),\n",
       " ('km', 0.4745),\n",
       " ('clin', 0.4672)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GetMostSimilar('zero', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', 1.0),\n",
       " ('romansh', 0.5165),\n",
       " ('languages', 0.3893),\n",
       " ('specialized', 0.3878),\n",
       " ('phonological', 0.3858),\n",
       " ('vocabulary', 0.3753),\n",
       " ('onomatopoeic', 0.3715),\n",
       " ('familiarity', 0.3679),\n",
       " ('microarrays', 0.3668),\n",
       " ('linguistics', 0.3659),\n",
       " ('synonymy', 0.3641),\n",
       " ('arabic', 0.3568),\n",
       " ('bengali', 0.3568),\n",
       " ('kanbun', 0.3564),\n",
       " ('re-examine', 0.356)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GetMostSimilar('language', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrorist', 1.0),\n",
       " ('bin', 0.5735),\n",
       " ('osama', 0.5588),\n",
       " ('ladin', 0.5467),\n",
       " ('pakistani', 0.5395),\n",
       " ('qaeda', 0.5385),\n",
       " ('jihad', 0.5349),\n",
       " ('terrorists', 0.5235),\n",
       " ('terrorism', 0.5019),\n",
       " ('ubl', 0.491),\n",
       " ('hamas', 0.4749),\n",
       " ('wmd', 0.4724),\n",
       " ('cia', 0.4703),\n",
       " ('laden', 0.4683),\n",
       " ('ressam', 0.4648)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GetMostSimilar('terrorist', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nasa', 1.0),\n",
       " ('aeronautics', 0.4482),\n",
       " ('lander', 0.445),\n",
       " ('foale', 0.4352),\n",
       " ('nih', 0.4207),\n",
       " ('shuttle', 0.4184),\n",
       " ('navfac', 0.4027),\n",
       " ('astronauts', 0.4007),\n",
       " ('orbiter', 0.4004),\n",
       " ('cosmonaut', 0.3996),\n",
       " ('tsibliev', 0.3976),\n",
       " ('align', 0.3902),\n",
       " ('mars', 0.3846),\n",
       " ('usace', 0.3828),\n",
       " ('astronaut', 0.3808)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.GetMostSimilar('nasa', 15)\n",
    "# Foale is an astrophysicist and former NASA astronaut.\n",
    "# Tsibliev is a cosmonaut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "A *Gensim Word2Vec Model* is trained with the same training corpus that was used for training our model. Then the performance metrics for the two models are computed on the training corpus to get a reference point (in order to reserve time, evaluation is done only on the first 1000 sentences of the training corpus). Further, the performances of the models are monitored on different test corpora with the increasing token sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from math import log, exp\n",
    "from collections import Counter\n",
    "\n",
    "def TrainGensimModel ( train_corpus_path ) :\n",
    "    file = open(train_corpus_path, 'r')\n",
    "    text = file.read()\n",
    "    text = text.lower()\n",
    "    file.close()\n",
    "    sents = [ word_tokenize(x) for x in sent_tokenize(text) ]\n",
    "    global gensim_model\n",
    "    gensim_model = Word2Vec(sents, min_count=6, size=300)\n",
    "    vocab1 = set(gensim_model.wv.vocab.keys())\n",
    "    vocab2 = set(model.__word_to_id_map__)\n",
    "    global VOCAB\n",
    "    VOCAB = vocab1.intersection(vocab2)\n",
    "    \n",
    "def GensimModelConditionalProbabilityDenominator ( center_word ) :\n",
    "    global GMCPD\n",
    "    if center_word in GMCPD : return GMCPD[center_word]\n",
    "    GMCPD[center_word] = 0.0\n",
    "    cwv = gensim_model.wv[center_word]\n",
    "    for word in VOCAB :\n",
    "        GMCPD[center_word] += exp(cwv.dot(gensim_model.wv[word]))\n",
    "    return GMCPD[center_word]\n",
    "\n",
    "def GensimModelConditionalProbability ( center , context ) :\n",
    "    num = exp(gensim_model.wv[context].dot(gensim_model.wv[center]))\n",
    "    den = GensimModelConditionalProbabilityDenominator(center)\n",
    "    return num / den\n",
    "\n",
    "def MyModelConditionalProbabilityDenominator ( center_word ) :\n",
    "    global MMCPD\n",
    "    if center_word in MMCPD : return MMCPD[center_word]\n",
    "    MMCPD[center_word] = 0.0\n",
    "    cwv = model[center_word]\n",
    "    for word in VOCAB : # VOCAB is the intersection of the VOCABs of both the models\n",
    "        MMCPD[center_word] += exp(cwv.dot(model[word]))\n",
    "    return MMCPD[center_word]\n",
    "\n",
    "def MyModelConditionalProbability ( center , context ) :\n",
    "    num = exp(model[context].dot(model[center]))\n",
    "    den = MyModelConditionalProbabilityDenominator(center)\n",
    "    return num / den\n",
    "\n",
    "def GensimModelPerformanceMetric ( center_context_pairs , token_count ) :\n",
    "    cost = 0.0\n",
    "    for (center, context), freq in center_context_pairs :\n",
    "        cost += freq * log( GensimModelConditionalProbability(center, context) )\n",
    "    cost *= ( -1 / token_count )\n",
    "    pred_acc = 1 / cost\n",
    "    pred_acc = 1 / ( 1 + exp(-1*pred_acc) )\n",
    "    return pred_acc\n",
    "\n",
    "def MyModelPerformanceMetric ( center_context_pairs , token_count ) :\n",
    "    cost = 0.0\n",
    "    for (center, context), freq in center_context_pairs :\n",
    "        val = MyModelConditionalProbability(center, context)\n",
    "        cost += freq * log( val )\n",
    "    cost *= ( -1 / token_count )\n",
    "    pred_acc = 1 / cost\n",
    "    pred_acc = 1 / ( 1 + exp(-1*pred_acc) )\n",
    "    return pred_acc\n",
    "\n",
    "def GenerateCenterContextPairs ( filepath , window , start = None , end = None ) :\n",
    "    file = open(filepath, 'r')\n",
    "    testtext = file.read()\n",
    "    testtext = testtext.lower()\n",
    "    file.close()\n",
    "    pairs = list()\n",
    "    T = 0\n",
    "    sents = sent_tokenize(testtext)\n",
    "    if not start is None : \n",
    "        if not end is None :\n",
    "            sents = sents[start:end]\n",
    "        else :\n",
    "            sents = sents[start:]\n",
    "    elif not end is None :\n",
    "        sents = sents[:end]\n",
    "    for sent in sents :\n",
    "        word_tokens = word_tokenize(sent)\n",
    "        refined = [x for x in word_tokens if x in VOCAB]\n",
    "        T += len(refined)\n",
    "        for ceni, center in enumerate(refined) :\n",
    "            for coni, context in enumerate(refined) :\n",
    "                if ( abs(ceni-coni) <= window and ceni != coni ) :\n",
    "                    pairs.append((center, context))\n",
    "    return list(Counter(pairs).items()), T\n",
    "\n",
    "def InitializeMaps ( ) :\n",
    "    global MMCPD, GMCPD\n",
    "    MMCPD, GMCPD = dict(), dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainGensimModel('TRAIN_CORPORA/CORPUS.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16625, 0.502063831703339, 0.5001855730001165)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs, token_count = GenerateCenterContextPairs('TRAIN_CORPORA/CORPUS.txt', 5, end = 1000)\n",
    "InitializeMaps()\n",
    "my_model_perf_metr = MyModelPerformanceMetric(pairs, token_count)\n",
    "gensim_model_perf_metr = GensimModelPerformanceMetric(pairs, token_count)\n",
    "token_count, my_model_perf_metr, gensim_model_perf_metr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1611, 0.5017167134921486, 0.5001708895156772)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs, token_count = GenerateCenterContextPairs('TEST_CORPORA/TEST1.txt', 5)\n",
    "InitializeMaps()\n",
    "my_model_perf_metr = MyModelPerformanceMetric(pairs, token_count)\n",
    "gensim_model_perf_metr = GensimModelPerformanceMetric(pairs, token_count)\n",
    "token_count, my_model_perf_metr, gensim_model_perf_metr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3301, 0.5016301419199041, 0.5001786122073575)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs, token_count = GenerateCenterContextPairs('TEST_CORPORA/TEST2.txt', 5, end = )\n",
    "InitializeMaps()\n",
    "my_model_perf_metr = MyModelPerformanceMetric(pairs, token_count)\n",
    "gensim_model_perf_metr = GensimModelPerformanceMetric(pairs, token_count)\n",
    "token_count, my_model_perf_metr, gensim_model_perf_metr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3929, 0.5016616919100826, 0.5001710064483414)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs, token_count = GenerateCenterContextPairs('TEST_CORPORA/TEST3.txt', 5)\n",
    "InitializeMaps()\n",
    "my_model_perf_metr = MyModelPerformanceMetric(pairs, token_count)\n",
    "gensim_model_perf_metr = GensimModelPerformanceMetric(pairs, token_count)\n",
    "token_count, my_model_perf_metr, gensim_model_perf_metr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5110, 0.50176414643688, 0.5001733606332893)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs, token_count = GenerateCenterContextPairs('TEST_CORPORA/TEST4.txt', 5)\n",
    "InitializeMaps()\n",
    "my_model_perf_metr = MyModelPerformanceMetric(pairs, token_count)\n",
    "gensim_model_perf_metr = GensimModelPerformanceMetric(pairs, token_count)\n",
    "token_count, my_model_perf_metr, gensim_model_perf_metr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6026, 0.501642867857437, 0.500176334821602)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs, token_count = GenerateCenterContextPairs('TEST_CORPORA/TEST5.txt', 5)\n",
    "InitializeMaps()\n",
    "my_model_perf_metr = MyModelPerformanceMetric(pairs, token_count)\n",
    "gensim_model_perf_metr = GensimModelPerformanceMetric(pairs, token_count)\n",
    "token_count, my_model_perf_metr, gensim_model_perf_metr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7035, 0.5017005127324882, 0.500176469930449)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs, token_count = GenerateCenterContextPairs('TEST_CORPORA/TEST6.txt', 5)\n",
    "InitializeMaps()\n",
    "my_model_perf_metr = MyModelPerformanceMetric(pairs, token_count)\n",
    "gensim_model_perf_metr = GensimModelPerformanceMetric(pairs, token_count)\n",
    "token_count, my_model_perf_metr, gensim_model_perf_metr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
